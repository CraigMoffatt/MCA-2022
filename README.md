# ✨ Craig's MCA Project ✨

## Week 1 Tasks

### Question 1 

The focus of my dataset will be the hit musical _Six:The Musical_ written by Toby Marlow and Lucy Moss. First premiered at the Edinburgh Fringe in 2017, the musical has swept the world as a hit phenomenon. Winning multiple awards the musical tells the stories of the six wives of King Henry VIII from their perspective and is about them reclaiming their stories. The musical is a lesson in both history and girl power and is a fun, enjoyable for anyone to enjoy!

![Six](https://user-images.githubusercontent.com/113994036/199851776-6014d4c6-760f-4308-80f3-0a2841b3a383.png)
(Figure 1.1 - *Six:The Musical* website) Screenshot taken from the [*Six:The Musical*](https://www.sixthemusical.com/) website


### Question 2 

Based on my own previous experiences, I do believe that many different challenges exist when collecting and working with music and music data. First of all, there is a strong chance you will find many conflicting opininos and answers to just about anything within datasets, both humans and programmes will all collect data within different ways and sometimes will come out with different answers and responses to what is given. Secondly dependent on the date of the piece you are trying to work on certain data surrounding what your looking for might not exist, for example if your piece is too modern, or too old certain details that you might be looking for might not be able to be found 

In regards to my chosen data set, I believe I will encounter both of these problems, moreso encountering the second issue. _Six: The Musical_ is a fairly new musical, only coming to London's west end in the last 5 years, so i believe that some of the data that I try to find might be a bit more difficult to come back but not impossible. However compared to musicals such as _Phantom of the Opera_ and _Funny Girl_, a lot of my data will require a lot of in depth searching 



## Week 2 Tasks

This weeks class tasked me with the task of identifying a piece of music from my dataset and downloading it as a PDF and then converting it into a musescore file, and then correcting any corrections that the converter may have had. Now as stated above my dataset is still fairly new, so I knew that I would struggle to find a free score online that was accurate to that of the actual musical. Thankfully I personally own the official book of sheet music sold on the website of the *Six:The Musical* which provides the vocal and piano sheet music for each of the queens individual songs, plus the opening track, the title track, and *Haus of Holbein*.

Now instead of downloading a million and one PDFs that may have been incorrect, I instead scanned in the first 2 pages of the sheet music for the title track *Six*, pasted the images into a word document and then converted that into a PDF. After a little messing around with the brightness of the scanned imagies, I was then able to convert this into a Musescore file.

Posted below are screenshots from the musescore file of the first 27 bars of *Six*. I chose this piece in particular as the beginning of the piece is very interesting and probably one of the most detailed out of all of the pieces within my book. It involves a tempo change at bar 11 changing from the slow lyrical opening to the upbeat pop song that the rest of the track is. It also features harmonies between the performers and gives each of the performers a couple of words to sing before coming together to create these harmonies. Finally once the tempo changes and before the individual lyrics for each of the performers start, the piano has a chance to shine, performing a complicated chord rhythm that when actually performed live is performed on the guitar as well (if not solely) and then proceeds to play a strong bass note on every beat consisting of two A flats an octave apart. To me this almost resembles a bass drum.

If you also desire, you can download my transcription of the score here!

![Score pg 1](https://user-images.githubusercontent.com/113994036/201171490-4e684464-76d4-4f0c-bca8-c296a9c47c91.PNG)

(Figure 2.1 - Transcription pg.1)

![Score pg2](https://user-images.githubusercontent.com/113994036/201171520-bcd49580-db08-49b7-aaa5-336f417c4cfa.PNG)

(Figure 2.2 - Transcription pg.2)

![Score pg3](https://user-images.githubusercontent.com/113994036/201171532-34bd17ed-8a87-418b-bd27-e9024c922c32.PNG)

(Figure 2.3 - Transcription pg.3)

## Week 3 Tasks 

This weeks task required me to take my score from last week, export it to both a MusicXML file and a MEI file, with taking the MEI file further into the Verovio editor.

Once completing this, I was tasked to compare three differences between MusicXML documentation and MEI documentation. 

The Results of these tasks can be found [here](https://craigmoffatt.github.io/MCA-2022/verovio.html)

## Week 4 Tasks

### Task 1 

My first task this week was to create a jSymbloic analysis of my piece, selecting a group of features for the programme to anaylse within the notated data of my piece 

The results of this task are shown below 

Feature|Result
--------------|-----------------
Pitch Class Histogram 0| 0.3481
Pitch Class Histogram 1| 0
Pitch Class Histogram 2| 0.08654
Pitch Class Histogram 3| 0
Pitch Class Histogram 4| 0.1365
Pitch Class Histogram 5| 0.1019
Pitch Class Histogram 6| 0
Pitch Class Histogram 7| 0.1692
Pitch Class Histogram 8| 0
Pitch Class Histogram 9| 0.1308
Pitch Class Histogram 10| 0
Pitch Class Histogram 11| 0.02692
Number of Pitches| 24
Number of Pitch Classes| 7
Range| 48
Strong Tonal Centres| 2
Mean Pitch| 60.58
Mean Pitch Class| 4.994
Most Common Pitch| 63
Most Common Pitch Class| 3
Interval Between Most Prevelant Pitches| 12
Pitch Variability| 10.19
Most Common Melodic Interval| 0
Repeated Notes| 0.2215
Melodic Thirds| 0.1368
Melodic Perfect Fourths| 0.09446
Melodic Tritones| 0
Melodic Perfect Fifths| 0.09121
Melodic Sixths| 0.1954
Melodic Sevenths| 0.03909
Melodic Octaves| 0.0684
Melodic Large Intervals| 0.009772
Most Common Vertical Interval| 0
Vertical Unisons| 0.03288
Vertical Minor Seconds| 0.00475
Vertical Thirds| 0.2328
Vertical Tritones| 0.000775
Vertical Perfect Fourths| 0.1437
Vertical Perfect Fifths| 0.1757
Vertical Sixths| 0.1282
Vertical Seveneths| 0.02043
Vertical Octaves| 0.2246
Perfect Vertical Intervals| 0.5768
Diminished and Augmented Triads| 0
Dominant Sevenths Chords| 0.01142
Seventh Chords| 0.09979
Mean Tempo| 112.4

All the data presented above comes from the feature values that I selected before instructing jSymbolic to run an analysis of my piece. I chose these features as I beleived they were the most interesting to look at, most of what I have selected require looking at the melodic features and harmonies of my piece and from trying to make sense of these I created feautes that were grouped into graphs, which are pasted below.

![image](https://user-images.githubusercontent.com/113994036/201692141-e1bf7d1b-d39c-4833-bdbe-c6bd82d77f31.png)

(Figure 4.1 - Pitch Class Histogram)

![image](https://user-images.githubusercontent.com/113994036/201692077-eeac5593-4ca8-4d27-b27c-1e87934a1a7a.png)

(Figure 4.2 - Melodic Intervals)

![image](https://user-images.githubusercontent.com/113994036/201691952-0998e65d-f5aa-48f4-8494-d2af8b70df74.png)

(Figure 4.3 - Vertical Intervals)

Figure 4.1 shows a Pitch Class Histogram of my piece. What we can understand from this is that within the analysis jSymbolic picked up that there are no sharps or flats in my piece, as the Numbers 0-11 go from C to B within the melodic scale, C=0 C sharp/D flat=1 D=2 etc. 

However, I do believe that jSymbolic has analysed this incorrectly. If you look back to the score posted in the week 2 tasks, you can see that my piece is in the key of E flat major which has 3 flats in the scale, being B, E and A - All of these notes feature in my piece according to my pitch class histogram however they have not registered as being flattened

### Task 2

The second task this week was to use python notebook to create further graphs of my piece using music21. 

![Music21 Graphy](https://user-images.githubusercontent.com/113994036/201697241-f595eda6-8336-4745-8484-a83dfdf17732.png)

(Figure 4.4 - Music21 Graph)

![My Scatter Plot](https://user-images.githubusercontent.com/113994036/201697252-4cd7ab49-8ad6-47c9-bc89-5aa1ee2ec3dd.png)

(Figure 4.5 - Scatter Plot)

![Note Quarter Length by Pitch](https://user-images.githubusercontent.com/113994036/201697269-35e6dc29-9693-4ebf-bba6-46e14a747c86.png)

(Figure 4.6 - Note Quarter Length By Pitch)

## Week 5

### Task 1

For the first task this week, I was tasked to create a metadata schema by listing the most important elements to my dataset, now as my dataset only contains a total of 9 tracks, I am slightly limited in numbers. However, if I were to put these all into my GitHub website, these are the details that I would encode as I believe that they would be the most important details

**Title** - The title of the track from the musical

**Author** - The author of the track - for my dataset, I believe that all of them have the same author, however it would still be worth including in the coding as to give credit to the writer

**Composer** - This follows the same trend as the author, I believe that they both have the same answers, so it would be up to the encoder which one they choose if not both

**Encoder** - The person encoding the file

**Date** - The data of the encoding and publication

**Size** - The size of the file to anyone wanting to download it

**Cast List** - As my piece is from a piece of musical theatre, I would include which characters performs the particular song, all of the pieces in my dataset are performed by all Six characters, however the balance is different in each of the songs, with some being performed by all of them together, and some being performed by one particular character with the other five providing back up vocals

### Task 2

For the second task this week, I was asked to take that metadata schema created from task 1, and to modify my MEI document in GitHub

The additions to my MEI file can be found below:
![WEEK 5 Task](https://user-images.githubusercontent.com/113994036/202449516-c6869520-b112-40b2-8b22-3344bd23cea7.PNG)
(Figure 5.1 - MEI additions)

## Week 7

## Week 8

### Task 1 

This week, I was first tasked to download three tracks relating to my dataset - The three tracks I chose came from the studio cast recording album which was the first recorded versions to be released on streaming services. My tracks consist of No Way, Heart of Stone, and All You Wanna Do - The mp3 tracks were downloaded from Amazon Music 

I chose each of these songs as they each have a different sound and style to them - No Way is the track within the show that has a lot of more Spanish style and features heavily on the drumming, even giving the drummer a solo in the middle of the track, sang by Catherine of Aragon. Heart of Stone is one of the two Ballads in the show sang by Jane Seymour, it stays the same tempo throughout the entirity of the track and is the song that provides pure raw emotion in the vocals. Finally, All You Wanna Do is the very heavy pop song of the show, sang by the character of Katherine Howard

To further emphasise this within the programme for the show, it states which artists that each characters style and vocals are inspired by. Catherine of Aragon is inspired by Shakira and Beyonce, Jane Seymour is inspired by, Katherine Howard is inspired by Ariana Grande and Britney Spears


After downloading these tracks, I created a table consisting of all the important technical and non-technical metadata associated with my tracks, the results of which are pasted below:

Metadata Title| Track 1| Track 2| Track 3|
--------------|--------|--------|--------|
Title| No Way| Heart of Stone| All You Wanna Do|
Artist| SIX, Renée Lamb| SIX, Natalie May Paris| SIX, Aimie Atkinson|
Composer| Lucy Moss, Toby Marlow| Lucy Moss, Toby Marlow| Lucy Moss, Toby Marlow|
Copyright Info| All rights reserved| All rights reserved| All rights reserved|
Genre| Musical Theatre| Musical Theatre| Musical Theatre|
Source| 6 Music Ltd a division of Loudmouth, under exclusive license from Ex-Wives Ltd| 6 Music Ltd a division of Loudmouth, under exclusive license from Ex-Wives Ltd| 6 Music Ltd a division of Loudmouth, under exclusive license from Ex-Wives Ltd|
File/Audio Format| MP3| MP3| MP3|
Sample Rate| 44100Hz| 44100Hz| 44100Hz|
Bits per second| 192 kb/s| 192 kb/s| 192 kb/sZ|
Bits per sample| 32| 32| 32|

### Task 2 

For the second task this week, I was tasked to take the waveform file that was created from Sonic Visualiser for each of the pieces and save them as an image, after this I created a spectrogram of each piece to then export to GitHub, the results of which are shown below

![No Way Waveform](https://user-images.githubusercontent.com/113994036/201958923-eb3f57fd-031d-4875-8bc0-4a1053be6e0e.png)
(Figure 8.1 - No Way Waveform)

![No Way Spectrogram(2)](https://user-images.githubusercontent.com/113994036/201961038-a8b237c1-80da-4d1d-b214-599cc02b5af2.png)
(Figure 8.2 - No Way Spectrogram)

![Heart of Stone Waveform](https://user-images.githubusercontent.com/113994036/201959128-a22ff02e-c27c-43cf-b9e6-f1085e219d27.png)
(Figure 8.3 - Heart of Stone Waveform)

![Heart of Stone Spectrogram(3)](https://user-images.githubusercontent.com/113994036/201960137-e3714df1-8f58-4776-9dfc-9f1472064763.png)
(Figure 8.4 - Heart of Stone Spectrogram)

![All you wanna do Waveform](https://user-images.githubusercontent.com/113994036/201958873-14b26f73-9de9-4959-a7bc-6ff14167e6f5.png)
(Figure 8.5 - All You Wanna Do Waveform)

![All you wanna do Spectrogram(2)](https://user-images.githubusercontent.com/113994036/201961551-4e9f3d16-bd15-4b22-950d-8de020d21730.png)
(Figure 8.6 - All You Wanna Do Spectrogram)

An advantange to time frequency analysis over waveform analysis would be that you can read the tempo, pitch and rhythm, if you look at the spectrograms for each of the tracks, you can see which notes occur more frequently and you can see how quickly they appear, from how red (a lot) or green (a little) the graph is at the specific point you are looking for. For example, if you look at All You Wanna Do (Figure 8.6) you can see that a lot of red appears very very quickly, my assumption is this is to do with how quick the piece is itself. Whereas if you compare it to Heart of Stone (Figure 8.4) you can see the amount of red drops immensely 


## Week 9

### Task 1 

This weeks first task was to take 30 second segments of pieces from our dataset and to create three panes to go alongside the waveform: a spectrogram, a Chromogram and a Mel Frequency Cepstral Coefficiants, using plugins for Sonic Visualiser

The results of which are shown below:

![No Way](https://user-images.githubusercontent.com/113994036/203315444-8fb2e55f-52c0-494e-99f9-9a0fe535ccb8.PNG)
(Figure 9.1 - No Way)

![Heart of Stone](https://user-images.githubusercontent.com/113994036/203315407-e30c5277-ae58-433f-86b1-736411feb21d.PNG)
(Figure 9.2 - Heart of Stone)


![All you Wanna Do](https://user-images.githubusercontent.com/113994036/203315387-2c87df39-81b0-4436-bbbc-a51781ba8019.PNG)
(Figure 9.3 - All You Wanna Do)

### Task 2

The second task this week was to use Jupyter Notebook to create histograms from the CSV files that we extracted from the Mel Frequency Cepstral Coefficiants pane

The results of which are shown below:

![No Way Histograms](https://user-images.githubusercontent.com/113994036/203784498-c35d0c2a-6b79-4e53-916d-afed316259e0.PNG)

(Figure 9.4 - No Way)

![Heart of Stone Histograms](https://user-images.githubusercontent.com/113994036/203784494-8dbad64b-256b-4ee8-8454-c1a515d133f1.PNG)

(Figure 9.5 - Heart of Stone)


![All You Wanna Do Histograms](https://user-images.githubusercontent.com/113994036/203784491-3123151a-cf3c-41fa-9a03-f2750b7491a9.PNG)

(Figure 9.6 - All You Wanna Do)

At a first glance, the histograms do not scream or highlight anything of significance. However, if you look at the histogram for All You Wanna Do, and No way you can see that the shapes of all the histograms are similar to each other. Even if the numbers are different the general shape follows the same trend. The same is somewhat true for Heart of Stone, with the exception of histograms: 0, 1 and 4. Where the histograms change their shape slightly. This does not scream anything with massive significance, other than what the frequency of the notes might be. However, looking at this for data such as the genre or the tempo of the piece, the data is very limited.



## Week 10

### Task 1

The first task this week was to use more python coding on Jupyter notebook to create similarity matrix's for the chromagrams of our three pieces. After replacing tracks 7-9 from the group lab on Tuesday, Jupyter gave out 2 similarity matrix's, shown below:

![Similarity Matrix 1](https://user-images.githubusercontent.com/113994036/203806160-e2ccde01-5149-4aca-a16f-18d06d6ab02c.PNG)
![Similarity Matrix 2](https://user-images.githubusercontent.com/113994036/203806162-5bf1f0d9-aa2b-4ad1-b2dc-7754ed579266.PNG)
(Figure 10.1 - Similarity Matrix's)


### Task 2 

The Final task was to create a WAV file of the score that I transcribed in Week 2, after that I took the file into sonic visualiser and created a transcription on there from the file. After doing that I exported the annotated layer as a MIDI file and had musescore transcribe that. 

During the task I encountered the issue that my piece was too big for the software to transcribe, so a segment of the first 30 seconds of my piece has been taken and transcribed.

The original first page and the transcription can be found below: 

![Score pg 1](https://user-images.githubusercontent.com/113994036/203806601-23802832-93f6-4580-8259-cb7723d2841c.PNG)

(Figure 10.2 - pg.1)

![sixexcerpt-1](https://user-images.githubusercontent.com/113994036/203806408-c02c5169-16ba-4240-a555-113c182fc0e7.png)
(Figure 10.3 - Transcription)

